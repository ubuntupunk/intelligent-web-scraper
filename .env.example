# Intelligent Web Scraper Environment Configuration
# Copy this file to .env and customize the values for your deployment

# =============================================================================
# CORE CONFIGURATION
# =============================================================================

# Environment (development, staging, production)
ENVIRONMENT=development

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Primary LLM provider (openai, gemini, deepseek, openrouter, anthropic)
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# Google Gemini Configuration
# GEMINI_API_KEY=your_gemini_api_key_here

# DeepSeek Configuration  
# DEEPSEEK_API_KEY=your_deepseek_api_key_here
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# OpenRouter Configuration
# OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Anthropic Configuration
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Legacy Azure OpenAI (for backward compatibility)
# AZURE_OPENAI_API_KEY=your_azure_api_key_here
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# LLM Models
ORCHESTRATOR_MODEL=gpt-4o-mini
PLANNING_AGENT_MODEL=gpt-4o-mini

# Model parameters (optional)
# TEMPERATURE=0.7
# MAX_TOKENS=2000
# TOP_P=1.0

# =============================================================================
# SCRAPING CONFIGURATION
# =============================================================================

# Quality and Performance
DEFAULT_QUALITY_THRESHOLD=50.0
MAX_CONCURRENT_REQUESTS=5
REQUEST_DELAY=1.0

# Output Configuration
EXPORT_FORMAT=json
RESULTS_DIRECTORY=./results

# =============================================================================
# COMPLIANCE AND ETHICS
# =============================================================================

# Ethical Scraping
RESPECT_ROBOTS_TXT=true
ENABLE_RATE_LIMITING=true

# User Agent String
USER_AGENT=Intelligent-Web-Scraper/0.1.0 (+https://github.com/atomic-agents/intelligent-web-scraper)

# Proxy Configuration (optional)
# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=http://proxy.example.com:8080
# NO_PROXY=localhost,127.0.0.1

# =============================================================================
# MONITORING AND LOGGING
# =============================================================================

# Monitoring
ENABLE_MONITORING=true
MONITORING_INTERVAL=1.0

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=text
LOG_DIRECTORY=./logs

# Metrics (optional)
# PROMETHEUS_ENABLED=true
# PROMETHEUS_PORT=8001

# =============================================================================
# CONCURRENCY AND PERFORMANCE
# =============================================================================

# Concurrency Configuration
MAX_INSTANCES=5
MAX_WORKERS=10
MAX_ASYNC_TASKS=50

# Memory and Resource Limits
# MEMORY_LIMIT=4G
# CPU_LIMIT=2.0

# =============================================================================
# DATABASE CONFIGURATION (OPTIONAL)
# =============================================================================

# PostgreSQL (for result storage)
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DB=scraper
# POSTGRES_USER=scraper
# POSTGRES_PASSWORD=scraper123

# Redis (for caching)
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_PASSWORD=scraper123
# REDIS_DB=0

# =============================================================================
# DOCKER CONFIGURATION
# =============================================================================

# Docker Compose Configuration
VERSION=latest
BUILD_DATE=
VCS_REF=

# Service Ports
APP_PORT=8000
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
REDIS_PORT=6379
POSTGRES_PORT=5432
NGINX_HTTP_PORT=80
NGINX_HTTPS_PORT=443

# Resource Limits
CPU_LIMIT=2.0
MEMORY_LIMIT=4G
CPU_RESERVATION=0.5
MEMORY_RESERVATION=1G

# Grafana Configuration
GRAFANA_USER=admin
GRAFANA_PASSWORD=admin

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# API Keys and Secrets
# JWT_SECRET=your_jwt_secret_here
# ENCRYPTION_KEY=your_encryption_key_here

# SSL/TLS Configuration (for production)
# SSL_CERT_PATH=/etc/ssl/certs/scraper.crt
# SSL_KEY_PATH=/etc/ssl/private/scraper.key

# =============================================================================
# DEVELOPMENT CONFIGURATION
# =============================================================================

# Development-specific settings
# DEBUG=true
# RELOAD=true
# DEV_MODE=true

# Testing Configuration
# TEST_DATABASE_URL=sqlite:///test.db
# TEST_OPENAI_API_KEY=test_key

# =============================================================================
# PRODUCTION CONFIGURATION
# =============================================================================

# Production-specific settings (uncomment for production)
# ENVIRONMENT=production
# LOG_LEVEL=WARNING
# LOG_FORMAT=json
# ENABLE_MONITORING=true
# MONITORING_INTERVAL=5.0
# MAX_CONCURRENT_REQUESTS=20
# DEFAULT_QUALITY_THRESHOLD=75.0
# REQUEST_DELAY=2.0

# Security settings for production
# RESPECT_ROBOTS_TXT=true
# ENABLE_RATE_LIMITING=true
# USER_AGENT=Intelligent-Web-Scraper/0.1.0 (Production; +https://your-domain.com/contact)

# =============================================================================
# CUSTOM CONFIGURATION
# =============================================================================

# Add your custom environment variables here
# CUSTOM_SETTING=value
# FEATURE_FLAG_ADVANCED_PARSING=true
# WEBHOOK_URL=https://your-webhook-endpoint.com/scraping-results